{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1726a3",
   "metadata": {},
   "source": [
    "# London Bikshare August 2023 Analysis\n",
    "\n",
    "## Instructions\n",
    "\n",
    "### Setup\n",
    "\n",
    "In order to run this Notebook you will need to upload the contents of `computed_data/` to the runtime of Google Colab.\n",
    "\n",
    "The variables in the next block are used to locate these files.\n",
    "\n",
    "If the files are in the root of the Colab project then these should work and have been tested. If, for any reason, the location has changed, please update `CALCULATED_DATASET_FOLDER`.\n",
    "\n",
    "### Sections\n",
    "\n",
    "The notebook is split into sections replicating spearate analysis files from the project.\n",
    "\n",
    "In some cases the visualisations are resource-intensive so have been commented out to prevent overloading your instance.\n",
    "\n",
    "## Main Dashboard\n",
    "\n",
    "The main component of the final analysis is a Dash application dashboard which allows users to select stations, weather events etc.\n",
    "\n",
    "The dashboard depends on the files from computed_data and is served with ngrok, a reverse proxy which should make the app visible in google Colab.\n",
    "\n",
    "This app has been placed at the end of the file to mitiate side effect errors on the other parts of the analysis should anything go wrong with ngrok.\n",
    "\n",
    "Once finished it is recommended to uncomment the section with `ngrok.kill()` and run it to ensure the app shuts down completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dash plotly pandas pyngrok dash_bootstrap_components kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc544f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "import dash_bootstrap_components as dbc\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from dash import callback, Dash, dcc, html, Input, Output\n",
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb829f",
   "metadata": {},
   "source": [
    "## File Locations\n",
    "\n",
    "Defines the locations of the computed files which the Notebook depends on.\n",
    "\n",
    "These are the computed results of successive calls to the TFL and OSM APIs and so should not be repeated unless ncessary.\n",
    "\n",
    "To re-generate the data the files prefixed with `setup_{number}` are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top-level folder containing the computed datasets.\n",
    "CALCULATED_DATASET_FOLDER = '.'\n",
    "\n",
    "# File to hold the result of the TFL API query.\n",
    "TFL_STATIONS = f'{CALCULATED_DATASET_FOLDER}/tfl-supplied-stations.json'\n",
    "\n",
    "# File to hold the result of the TFL API query.\n",
    "TFL_FILTERED = f'{CALCULATED_DATASET_FOLDER}/tfl-supplied-stations-selected.json'\n",
    "\n",
    "# File to hold the result of the OSM API query.\n",
    "OSM_STATIONS = f'{CALCULATED_DATASET_FOLDER}/osm-supplied-stations.json'\n",
    "\n",
    "# File to hold the result of re-queried data from the OSM query.\n",
    "OSM_FILTERED = f'{CALCULATED_DATASET_FOLDER}/osm-supplied-stations-selected.json'\n",
    "\n",
    "# File with the combined station data from all sources.\n",
    "COMBINED_STATIONS = f'{CALCULATED_DATASET_FOLDER}/combined-stations.json'\n",
    "\n",
    "# File with the combined station data in list / array format.\n",
    "COMBINED_STATIONS_LIST = f'{CALCULATED_DATASET_FOLDER}/combined-stations-list.json'\n",
    "\n",
    "TFL_APP_ID = 'edb827fb3ce148daabed9b52433afdc5'\n",
    "NGROK_TOKEN = '37su9a95SFgEvM3q8sMkNf6SwPb_dAv5YCeUd1ESrobYsM9n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f495579",
   "metadata": {},
   "source": [
    "## Main Datasets Setup & Unique Origin-Destination (OD) Calculation\n",
    "\n",
    "Downloads and loads in the datasets, sets config variables, and cleans date columns ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88103a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "\n",
    "# Download latest version of the main dataset.\n",
    "bike_data_path = kagglehub.dataset_download('kalacheva/london-bike-share-usage-dataset')\n",
    "weather_data_path = kagglehub.dataset_download('zongaobian/london-weather-data-from-1979-to-2023')\n",
    "\n",
    "print('Path to bike dataset file:', bike_data_path)\n",
    "print('Path to weather dataset file:', weather_data_path)\n",
    "\n",
    "# Load in bike share dataset and weather data\n",
    "df_bike_data = pd.read_csv(\n",
    "    f'{bike_data_path}/LondonBikeJourneyAug2023.csv'\n",
    ")\n",
    "df_weather_data = pd.read_csv(\n",
    "    f'{weather_data_path}/london_weather_data_1979_to_2023.csv'\n",
    ")\n",
    "\n",
    "# Format date columns to datetime\n",
    "df_bike_data['Start date'] = pd.to_datetime(\n",
    "    df_bike_data['Start date'], format='%m/%d/%Y %H:%M'\n",
    ")\n",
    "df_bike_data['End date'] = pd.to_datetime(\n",
    "    df_bike_data['End date'], format='%m/%d/%Y %H:%M'\n",
    ")\n",
    "\n",
    "df_bike_data['date_hour'] = df_bike_data['Start date'].dt.floor('h')  # type: ignore\n",
    "df_bike_data['date_day'] = df_bike_data['Start date'].dt.floor('d')  # type: ignore\n",
    "\n",
    "df_weather_data['date_formatted'] = pd.to_datetime(df_weather_data['DATE'], format='%Y%m%d')\n",
    "\n",
    "# Verify the data read was successful.\n",
    "print(df_bike_data)\n",
    "print(len(df_bike_data['Start station'].unique()))\n",
    "\n",
    "# Create a new df_bike_data which contains a list of all unique trips (origin-destination pairs) and the quantity counts for each.\n",
    "df_unique_od = (\n",
    "    df_bike_data.groupby(['Start station', 'End station'])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: 'count'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e957ca0",
   "metadata": {},
   "source": [
    "## Interrogating Unique OD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fddfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a precursory glance at all trips which only appear once, twice, etc up to 10, assuming a quick drop-off.\n",
    "# The results are noted in commas following for quick reference, do not assume these are unchanged.\n",
    "print(df_unique_od)\n",
    "print('1 trip occurrences: ', df_unique_od['count'].value_counts().get(1))  # 76943\n",
    "print('2 trip occurrences: ', df_unique_od['count'].value_counts().get(2))  # 36612\n",
    "print('3 trip occurrences: ', df_unique_od['count'].value_counts().get(3))  # 20516\n",
    "print('4 trip occurrences: ', df_unique_od['count'].value_counts().get(4))  # 13231\n",
    "print('5 trip occurrences: ', df_unique_od['count'].value_counts().get(5))  # 9195\n",
    "print('6 trip occurrences: ', df_unique_od['count'].value_counts().get(6))  # 6403\n",
    "print('7 trip occurrences: ', df_unique_od['count'].value_counts().get(7))  # 4907\n",
    "print('8 trip occurrences: ', df_unique_od['count'].value_counts().get(8))  # 3871\n",
    "print('9 trip occurrences: ', df_unique_od['count'].value_counts().get(9))  # 2988\n",
    "print('10 trip occurrences: ', df_unique_od['count'].value_counts().get(10))  # 2439\n",
    "# Total <= 10 trips: 177105\n",
    "# Total > 10 trips: 191630 - 177105 = 14525\n",
    "\n",
    "# Take the largest number of repeat trips for reference (York Way, KX).\n",
    "print('Max repeat values: ', df_unique_od.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59be728",
   "metadata": {},
   "source": [
    "### Number of trips by start station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From vis_highest_repeat_unique_od.py\n",
    "x_axis_quant = 20\n",
    "df_sorted = df_unique_od.sort_values('count', ascending=False).reset_index().head(x_axis_quant)\n",
    "print(df_sorted)\n",
    "\n",
    "fig = px.bar(df_sorted, x='Start station', y='count')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb72380",
   "metadata": {},
   "source": [
    "## Circular Trips and False Starts\n",
    "\n",
    "For a given start station, defaulted to \"York Way, Kings Cross\", calculate the number of rides which end at the same station, and make an esitmation of how many of these are \"False Starts\"; trips which were abandoned early indicating a bike fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb86874",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_station = 'York Way, Kings Cross'\n",
    "\n",
    "# Find a subset of data matching YW, Kings Cross as a start station. This will for the basis of later queries examining the validity of this subset.\n",
    "print('All from KX: ')\n",
    "print(df_bike_data.loc[df_bike_data['Start station'] == target_station])\n",
    "\n",
    "# We assume that trips under 60 seconds are potential \"false starts\". Select how many fall into this category.\n",
    "print('All from KX under 1 minute: ')\n",
    "print(\n",
    "    df_bike_data.loc[df_bike_data['Start station'] == target_station]['Total duration (ms)']\n",
    "    .apply(lambda x: x < 60000)\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# Given very few are potential \"false starts\", we must assume these are circular trips.\n",
    "# How many unique OD trips are circular?\n",
    "print('Unique Start station and End station are the same: ')\n",
    "print(\n",
    "    df_unique_od.loc[\n",
    "        df_unique_od['Start station'] == df_unique_od['End station']\n",
    "    ].reset_index()\n",
    ")\n",
    "\n",
    "# How many trips are circular in the entire dataset?\n",
    "print('Full DF Start station and End station are the same: ')\n",
    "print(df_bike_data.loc[df_bike_data['Start station'] == df_bike_data['End station']].reset_index())\n",
    "\n",
    "# Of this, how many are potential \"false starts\"?\n",
    "print('Full DF Start station and End station are the same and less than 60 seconds: ')\n",
    "print(\n",
    "    df_bike_data.loc[df_bike_data['Start station'] == df_bike_data['End station']]['Total duration (ms)']\n",
    "    .apply(lambda x: x < 60000)\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f6bfb",
   "metadata": {},
   "source": [
    "## Number of Repeat Trips by Count\n",
    "\n",
    "Aggregates the number of repeat trips vs their count in the dataset.\n",
    "\n",
    "E.g. 1 would indicate trips which appear only once, 2 is trips with two entries and so on.\n",
    "\n",
    "Creates a DF to sample some of these and plots the rest on a scatterplot, with a cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple scatter plot of the unique OR trip df.\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# Given the maximum value from `df_unique_od.max()` set the max x-axis of the chart to 3000. Ignore 0 as there cannot be 0 trips.\n",
    "for i in range(1, 3000):\n",
    "    # Loop over the trip quantity, query how many counts there are in the unique OD set.\n",
    "    x.append(i)\n",
    "    y_val = int(df_unique_od['count'].value_counts().get(i, 0))\n",
    "    y.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the steep x-axis drop off, we'll cut the graph at 145 to focus on the lower end.\n",
    "cut_off = 145\n",
    "\n",
    "x_left = x[:cut_off]\n",
    "x_right = x[cut_off:]\n",
    "y_left = y[:cut_off]\n",
    "y_right = y[cut_off:]\n",
    "\n",
    "# Create a table of the outliers for interest.\n",
    "outliers = []\n",
    "\n",
    "for idx, x_val in enumerate(x_right):\n",
    "    if y_right[idx] != 0:\n",
    "        outliers.append((x_val, y_right[idx]))\n",
    "\n",
    "print(f'outliers ({len(outliers)}): ', outliers)\n",
    "\n",
    "df_outliers = pd.DataFrame(\n",
    "    outliers, columns=['Number of repetitions', 'Quantity of trips']\n",
    ")\n",
    "\n",
    "print('Outliers df:')\n",
    "print(df_outliers)\n",
    "\n",
    "df_outliers.to_csv('unique-od-outliers-145-cutoff.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226dc7db",
   "metadata": {},
   "source": [
    "### Run Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the graph\n",
    "fig = px.scatter(\n",
    "    x=x_left,\n",
    "    y=y_left,\n",
    "    title='Frequency of Repeat Trips',\n",
    "    labels={'x': 'Number of repeat trips', 'y': 'Quantity of trips'},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d47bc9",
   "metadata": {},
   "source": [
    "## Total Pickups Per Start Station\n",
    "\n",
    "Visualises the number of total pickups per start station across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From vis_total_pickups_sorted.py\n",
    "# Create a new df which contains a list of all unique trips (origin-destination pairs) and the quantity counts for each.\n",
    "df_sorted = (\n",
    "    df_bike_data.groupby(['Start station'])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: 'count'})\n",
    "    .sort_values('count', ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "print(df_sorted)\n",
    "\n",
    "fig = px.bar(df_sorted, x='Start station', y='count')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7cd7ae",
   "metadata": {},
   "source": [
    "## Trip Count or Avg Duration vs Precipitation\n",
    "\n",
    "Depending on comments, plots either the trip count or duration versus Precipitation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From vis_weather_vs_count_or_duration\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    left=df_bike_data,\n",
    "    right=df_weather_data,\n",
    "    left_on=['date_day'],\n",
    "    right_on=['date_formatted'],\n",
    ")\n",
    "\n",
    "hourly_agg = (\n",
    "    df_merged.groupby('date_hour')\n",
    "    # df_bike_data.groupby(['date_hour', 'Start station', 'End station'])\n",
    "    .agg(\n",
    "        avg_duration_ms=('Total duration (ms)', 'mean'),\n",
    "        trip_count=('Number', 'count'),\n",
    "        rain=('RR', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=hourly_agg['date_hour'],\n",
    "        y=hourly_agg['trip_count'],\n",
    "        mode='lines',\n",
    "        name='Trips Started',\n",
    "        yaxis='y1',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=hourly_agg['date_hour'],\n",
    "        y=hourly_agg['rain'],\n",
    "        mode='lines',\n",
    "        name='Precipitation',\n",
    "        yaxis='y2',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average Trip Duration and Trip Volume per Hour (August 2023)',\n",
    "    xaxis=dict(title='hour'),\n",
    "    yaxis=dict(title='Average Trip Duration (ms)', side='left'),\n",
    "    yaxis2=dict(title='Number of Trips Started', overlaying='y', side='right'),\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ede1f7",
   "metadata": {},
   "source": [
    "## Visualise average trip duration by Time\n",
    "\n",
    "NOTE: This visualisation is intensive and may slow your Colab / Notebook instance.\n",
    "\n",
    "Uncomment to re-enable and run with this in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_bike_data.sort_values(by='Start date', inplace=True, ascending=False)\n",
    "# plot2 = px.scatter(df_bike_data, x='Start date', y='Total duration (ms)')\n",
    "# plot2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19308d4c",
   "metadata": {},
   "source": [
    "## Main Dash Dashboard Application & Dynamic Visualisation\n",
    "\n",
    "Runs a dhas app served using ngrok.\n",
    "\n",
    "Once finished it is recommended to uncomment the next block with `ngrok.kill()` to ensure correct shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather_keys = {\n",
    "    'TX': 'Daily maximum temperature in 0.1°C.',\n",
    "    'TN': 'Daily minimum temperature in 0.1°C.',\n",
    "    'TG': 'Daily mean temperature in 0.1°C.',\n",
    "    'SS': 'Daily sunshine duration in 0.1 hours.',\n",
    "    'SD': 'Daily snow depth in 1 cm.',\n",
    "    'RR': 'Daily precipitation amount in 0.1 mm.',\n",
    "    'QQ': 'Daily global radiation in W/m².',\n",
    "    'PP': 'Daily sea level pressure in 0.1 hPa.',\n",
    "    'HU': 'Daily relative humidity in %.',\n",
    "    'CC': 'Daily cloud cover in oktas.',\n",
    "}\n",
    "\n",
    "df_stations = pd.read_json(COMBINED_STATIONS)\n",
    "\n",
    "df_bike_data_parsed = pd.merge(\n",
    "    df_bike_data,\n",
    "    df_stations,\n",
    "    left_on=['Start station'],\n",
    "    right_on=['bikeDataStationName'],\n",
    ")\n",
    "\n",
    "# Ensure Start date is parsed as datetime\n",
    "df_bike_data_parsed['Start date'] = pd.to_datetime(df_bike_data_parsed['Start date'])\n",
    "\n",
    "print('>>> df_bike_data_parsed')\n",
    "print(df_bike_data_parsed)\n",
    "print(df_bike_data_parsed.columns)\n",
    "\n",
    "# Extract date (day-level)\n",
    "df_bike_data_parsed['date_hour'] = df_bike_data_parsed['Start date'].dt.floor('h')  # type: ignore\n",
    "df_bike_data_parsed['date_day'] = df_bike_data_parsed['Start date'].dt.floor('d')  # type: ignore\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    left=df_bike_data_parsed,\n",
    "    right=df_weather_data,\n",
    "    left_on=['date_day'],\n",
    "    right_on=['date_formatted'],\n",
    ")\n",
    "\n",
    "app = Dash(\n",
    "    external_stylesheets=[dbc.themes.BOOTSTRAP],\n",
    ")\n",
    "\n",
    "test = df_merged['date_day'].unique()\n",
    "print('>> test', test)\n",
    "\n",
    "# the style arguments for the sidebar. We use position:fixed and a fixed width\n",
    "SIDEBAR_STYLE = {\n",
    "    'position': 'fixed',\n",
    "    'top': 0,\n",
    "    'left': 0,\n",
    "    'bottom': 0,\n",
    "    'width': '20%',\n",
    "    'padding': '2rem 1rem',\n",
    "    'background-color': '#f8f9fa',\n",
    "    'font-size': '13px',\n",
    "}\n",
    "\n",
    "# the styles for the main content position it to the right of the sidebar and\n",
    "# add some padding.\n",
    "CONTENT_STYLE = {\n",
    "    'margin-left': '18rem',\n",
    "    'margin-right': '2rem',\n",
    "    'padding': '2rem 1rem',\n",
    "}\n",
    "\n",
    "sidebar = html.Div(\n",
    "    [\n",
    "        html.H2('Mode'),\n",
    "        dcc.RadioItems(\n",
    "            options=[\n",
    "                {'value': 'all', 'label': 'All data'},\n",
    "                {'value': 'station', 'label': 'By start station'},\n",
    "            ],\n",
    "            value='all',\n",
    "            id='radio-mode',\n",
    "        ),\n",
    "        dcc.Dropdown(\n",
    "            df_bike_data['Start station'].unique(),  # type: ignore\n",
    "            id='dropdown-start_station',\n",
    "        ),\n",
    "        dcc.Checklist(\n",
    "            [{'value': 'use_ratio', 'label': 'Show weather metric as ratio'}],\n",
    "            value=['use_ratio'],\n",
    "            id='checkbox-use_ratio',\n",
    "        ),\n",
    "        html.Hr(),\n",
    "        html.H2('Trip Data'),\n",
    "        dcc.RadioItems(\n",
    "            options=[\n",
    "                {'label': 'Trip count', 'value': 'count'},\n",
    "                {'label': 'Avg. Duration', 'value': 'duration'},\n",
    "            ],\n",
    "            value='count',\n",
    "            id='radio-compare',\n",
    "        ),\n",
    "        html.Hr(),\n",
    "        html.H2('Weather Data'),\n",
    "        dcc.RadioItems(\n",
    "            options=[\n",
    "                {'value': value, 'label': label}\n",
    "                for value, label in weather_keys.items()\n",
    "            ],\n",
    "            value='RR',\n",
    "            id='radio-weather',\n",
    "        ),\n",
    "    ],\n",
    "    style=SIDEBAR_STYLE,\n",
    ")\n",
    "\n",
    "content = html.Div(\n",
    "    [\n",
    "        dcc.RangeSlider(1, 31, 1, value=[1, 31], id='range-date'),\n",
    "        dcc.Graph(id='graph-line'),\n",
    "        dcc.Graph(id='graph-scatter'),\n",
    "    ],\n",
    "    style=CONTENT_STYLE,\n",
    ")\n",
    "\n",
    "app.layout = [\n",
    "    html.H1(\n",
    "        children='Weather events vs Trips whole month', style={'textAlign': 'center'}\n",
    "    ),\n",
    "    sidebar,\n",
    "    content,\n",
    "]\n",
    "\n",
    "print('>>> df_merged')\n",
    "print(df_merged)\n",
    "print(df_merged.columns)\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output('graph-line', 'figure'),\n",
    "    Output('graph-scatter', 'figure'),\n",
    "    Input('radio-compare', 'value'),\n",
    "    Input('radio-weather', 'value'),\n",
    "    Input('radio-mode', 'value'),\n",
    "    Input('dropdown-start_station', 'value'),\n",
    "    Input('checkbox-use_ratio', 'value'),\n",
    "    Input('range-date', 'value'),\n",
    ")\n",
    "def graph(\n",
    "    compare_mode: str,\n",
    "    weather: str,\n",
    "    mode: str,\n",
    "    start_station: str,\n",
    "    use_ratio: List[str],\n",
    "    range_date: List[int],\n",
    "):\n",
    "    start_date = datetime(2023, 8, range_date[0])\n",
    "    end_date = datetime(2023, 8, range_date[1], 23, 59, 59)\n",
    "\n",
    "    print('start date: ', start_date)\n",
    "    print('end date: ', end_date)\n",
    "\n",
    "    date_mask = (df_merged['date_day'] >= start_date) & (\n",
    "        df_merged['date_day'] <= end_date\n",
    "    )\n",
    "\n",
    "    if mode == 'station':\n",
    "        mask = (df_merged['Start station'] == start_station) & date_mask\n",
    "        dff = df_merged[mask]\n",
    "    else:\n",
    "        dff = df_merged[date_mask]\n",
    "\n",
    "    y1_label = (\n",
    "        'Average Trip Duration (ms)' if compare_mode == 'duration' else 'Trips Started'\n",
    "    )\n",
    "    trip_key = 'avg_duration_ms' if compare_mode == 'duration' else 'trip_count'\n",
    "\n",
    "    print('>>> dff')\n",
    "    print(dff)\n",
    "    print(dff.columns)\n",
    "\n",
    "    hourly_agg = (\n",
    "        dff.groupby('date_hour')\n",
    "        .agg(\n",
    "            avg_duration_ms=('Total duration (ms)', 'mean'),\n",
    "            trip_count=('Number', 'count'),\n",
    "            weather_agg=(weather, 'mean'),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    hourly_agg['ratio'] = hourly_agg[trip_key] / hourly_agg['weather_agg']\n",
    "\n",
    "    fig_line = go.Figure()\n",
    "\n",
    "    fig_line.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hourly_agg['date_hour'],\n",
    "            y=hourly_agg[trip_key],\n",
    "            mode='lines',\n",
    "            name=y1_label,\n",
    "            yaxis='y1',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig_line.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hourly_agg['date_hour'],\n",
    "            y=hourly_agg['ratio' if 'use_ratio' in use_ratio else 'weather_agg'],\n",
    "            mode='lines',\n",
    "            name=weather_keys[weather],\n",
    "            yaxis='y2',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig_line.update_layout(\n",
    "        title='Average Trip Duration and Trip Volume per Hour (August 2023)',\n",
    "        xaxis=dict(title='hour'),\n",
    "        yaxis=dict(title=y1_label, side='left'),\n",
    "        yaxis2=dict(title=weather_keys[weather], overlaying='y', side='right'),\n",
    "        legend=dict(x=0.01, y=0.99),\n",
    "    )\n",
    "\n",
    "    fig_scatter = px.scatter_map(\n",
    "        df_stations,\n",
    "        lat='lat',\n",
    "        lon='lon',\n",
    "        hover_data=['name', 'lat', 'lon'],\n",
    "        zoom=11,\n",
    "    )\n",
    "\n",
    "    if mode == 'station':\n",
    "        df_scatter_filter = dff[dff['Start station'] == start_station]\n",
    "        df_scatter_grouped = (\n",
    "            df_scatter_filter.groupby(['Start station', 'End station'])\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: 'count'})\n",
    "        )\n",
    "        df_scatter = pd.merge(\n",
    "            df_scatter_grouped,\n",
    "            df_stations,\n",
    "            left_on=['End station'],\n",
    "            right_on=['bikeDataStationName'],\n",
    "        )\n",
    "\n",
    "        start_station_data = df_stations[\n",
    "            df_stations['bikeDataStationName'] == start_station\n",
    "        ].reset_index()\n",
    "        if len(start_station_data):\n",
    "            start_station_data = start_station_data.iloc[0]\n",
    "\n",
    "            for i in range(len(df_scatter)):\n",
    "                fig_scatter.add_trace(\n",
    "                    go.Scattermap(\n",
    "                        lon=[start_station_data['lon'], df_scatter['lon'][i]],\n",
    "                        lat=[start_station_data['lat'], df_scatter['lat'][i]],\n",
    "                        mode='lines',\n",
    "                        opacity=1,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        pass\n",
    "\n",
    "    return fig_line, fig_scatter\n",
    "\n",
    "# Start the app in a thread\n",
    "def run_app():\n",
    "    app.run()\n",
    "\n",
    "thread = threading.Thread(target=run_app)\n",
    "thread.start()\n",
    "\n",
    "# Open ngrok tunnel\n",
    "public_url = ngrok.connect(8050)\n",
    "print('App is live at:', public_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a605000",
   "metadata": {},
   "source": [
    "Shut-down the ngrok reverse proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrok.kill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
